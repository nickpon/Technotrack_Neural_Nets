{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3UoKiE0t1Pkd"
   },
   "outputs": [],
   "source": [
    "#!pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.1.post2-cp36-cp36m-linux_x86_64.whl\n",
    "#!pip3 install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D7IBizZ1UDEw"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "import random\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For showing good progress bars.\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mu8nF_Y08vEj"
   },
   "outputs": [],
   "source": [
    "#отключает warnings pytorch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "fmbdqpWDzBb5",
    "outputId": "5adc6eed-9209-4e9b-bf11-238cc1e50a8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1.post2\n",
      "True\n",
      "1 Tesla K80\n",
      "0\n",
      "<torch.cuda.device object at 0x7fa1f5fc8b38>\n",
      "CudaVersion :  10.0.130\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "print(torch.cuda.device_count(), torch.cuda.get_device_name(0))\n",
    "\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(\"CudaVersion : \",torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Ov-7o7eyJGB"
   },
   "outputs": [],
   "source": [
    "DEVICE_ID = 0\n",
    "DEVICE = torch.device('cuda:%d' % DEVICE_ID)\n",
    "torch.cuda.set_device(DEVICE_ID)\n",
    "\n",
    "### Для запуска без GPU раскомментировать и закоментировать код выше\n",
    "# DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pQkqFyVFyUm0"
   },
   "outputs": [],
   "source": [
    "np.random.seed(100500)\n",
    "\n",
    "def data2image(data):\n",
    "    res = np.transpose(np.reshape(data ,(3, 32,32)), (1,2,0))\n",
    "    return PIL.Image.fromarray(np.uint8(res))\n",
    "\n",
    "def imshow(img):\n",
    "    if isinstance(img, torch.Tensor): img = img.numpy().astype('uint8')\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    \n",
    "def prediction2classes(output_var):\n",
    "    _, predicted = torch.max(output_var.data, 1)\n",
    "    predicted.squeeze_()\n",
    "    classes = predicted.tolist()\n",
    "    return classes\n",
    "\n",
    "def make_solution_pytorch(net, input_tensor, a_batch_size):\n",
    "    res = []\n",
    "    net = net.eval()\n",
    "    cur_pos = 0\n",
    "    while cur_pos <= len(input_tensor):\n",
    "        outputs = net(input_tensor[cur_pos:cur_pos+a_batch_size])\n",
    "        res += prediction2classes(outputs)\n",
    "        cur_pos += a_batch_size\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06AeKEiWUa-h"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "\n",
    "class CifarDataset(Dataset):\n",
    "    def __init__(self, input_path, is_train=True, transform=None):\n",
    "                        \n",
    "        data = np.load(input_path)\n",
    "        if is_train: \n",
    "            self.Y, self.X = np.hsplit(data, [1]) \n",
    "            self.Y = [item[0] for item in self.Y]\n",
    "        else: \n",
    "            self.X = data\n",
    "            self.Y = None\n",
    "            \n",
    "        self.X = self.X.reshape((self.X.shape[0], 3, 32, 32))\n",
    "        self.X = self.X.transpose((0, 2, 3, 1)) #приводим к виду (N, H, W, C)\n",
    "        self.X = [Image.fromarray(img) for img in self.X]\n",
    "                \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample = self.X[idx]\n",
    "\n",
    "        if self.transform: sample = self.transform(sample)\n",
    "\n",
    "        if self.Y is None: return sample\n",
    "        else: return (sample, self.Y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "omG-yDCAVk85",
    "outputId": "dc4641e4-d046-4869-e616-29766e7fef6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "Mo_tFzOVwilF",
    "outputId": "143e7345-6c8b-442d-fda5-d9e06a83764b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " homework_4_no_classes.test.npy     my_solution_resnet_wide_6.csv\n",
      " homework_4.train.npy\t\t    my_solution_wide_r_1.csv\n",
      " Kaggle_HW4.ipynb\t\t    my_solution_wide_r_2.csv\n",
      "'Kaggle_HW4_ResNet_py3 (1).ipynb'   my_solution_wide_r_3.csv\n",
      " my_damn_results\t\t    my_solution_wide_r_5.csv\n",
      " my_solution_lenet.csv\t\t    my_solution_wide_r_6.csv\n",
      " my_solution_res_2.csv\t\t   'ResNet_HW4 (3).ipynb'\n",
      " my_solution_res_3.csv\t\t    ResNet_HW4.ipynb\n",
      " my_solution_res.csv\t\t    sample_submission.csv\n",
      " my_solution_resnet_wide_4.csv\n"
     ]
    }
   ],
   "source": [
    "#тут папки с проблема должны быть заключены в \"\"\n",
    "PATH_OF_DATA= '/content/gdrive/\"My Drive\"/\"Technotrack_hw_4\"/'\n",
    "!ls {PATH_OF_DATA}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r-MYsKTfw2ZW"
   },
   "outputs": [],
   "source": [
    "#Тут папки с пробелами НЕ надо заключать в \"\"\n",
    "DATA_PATH  = '/content/gdrive/My Drive/Technotrack_hw_4/'\n",
    "train_path = 'homework_4.train.npy'\n",
    "test_path  = 'homework_4_no_classes.test.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8gM30XxszmwA"
   },
   "outputs": [],
   "source": [
    "np_mean = np.mean([item[0].numpy() for item in CifarDataset(DATA_PATH + train_path, transform=transforms.ToTensor())], axis=(0,2,3))\n",
    "np_std = np.std([item[0].numpy() for item in CifarDataset(DATA_PATH + train_path, transform=transforms.ToTensor())], axis=(0,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_35tkhs9zrpi",
    "outputId": "0fb38071-57c1-48fe-9637-2b1bcad0b0ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.50760865, 0.48708203, 0.44149536], dtype=float32), (3,))"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_mean, np_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vUnHdWIDz0TB",
    "outputId": "f216bfbf-ff58-491d-ec21-8a7f6be78c3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.26764476, 0.2567687 , 0.27647924], dtype=float32), (3,))"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_std, np_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rqv5HTGPz1UL"
   },
   "outputs": [],
   "source": [
    "cifar_transform_norm = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.FloatTensor(np_mean), torch.FloatTensor(np_std))\n",
    "]\n",
    ")\n",
    "\n",
    "cifar_test_transform_norm = transforms.Compose([    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.FloatTensor(np_mean), torch.FloatTensor(np_std))\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oJmzKcvRz8Pe"
   },
   "outputs": [],
   "source": [
    "dataset_train_norm = CifarDataset(DATA_PATH + train_path, transform=cifar_transform_norm)\n",
    "dataloader_train_norm = DataLoader(dataset_train_norm, batch_size=128,\n",
    "                        shuffle=True, num_workers=4)\n",
    "\n",
    "dataset_test_norm = CifarDataset(DATA_PATH + test_path, is_train=False, transform=cifar_test_transform_norm)\n",
    "dataloader_test_norm = DataLoader(dataset_test_norm, batch_size=128,\n",
    "                        shuffle=False, num_workers=1)\n",
    "\n",
    "\n",
    "def train_network(a_net, \n",
    "                  a_device,\n",
    "                  dataloader_train_norm=dataloader_train_norm,\n",
    "                  a_epochs=164,\n",
    "                  a_batch_size=128,\n",
    "                  a_lr=0.1):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_acc = []\n",
    "    #a_net = torch.load('/content/gdrive/My Drive/my_damn_results_2_20x5')\n",
    "    net = a_net.to(a_device)\n",
    "    \n",
    "    # Google Colab warks quite bizzare. It has a tendency to lose connection. From\n",
    "    # here comes the main importance to store a model's parameters not to lose all results.\n",
    "    #net.load_state_dict(torch.load('/content/gdrive/My Drive/my_damn_results_2_20x5'))\n",
    "    #net = torch.load('/content/gdrive/My Drive/my_damn_results_2_20x5')\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr, weight_decay=0.0001, momentum=0.9)\n",
    "\n",
    "    prev_epoch_time = start_time\n",
    "    \n",
    "    my_solution = 0\n",
    "    \n",
    "    for epoch in range(93, a_epochs):  # loop over the dataset multiple times\n",
    "#         if epoch == 82:\n",
    "#             optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr/10, weight_decay=0.0001, momentum=0.9) \n",
    "#         elif epoch == 123:\n",
    "#             optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr/100, weight_decay=0.0001, momentum=0.9)\n",
    "\n",
    "        if epoch == 62:\n",
    "            optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr/10, weight_decay=0.0001, momentum=0.9) \n",
    "        elif epoch == 93:\n",
    "            optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr/100, weight_decay=0.0001, momentum=0.9) \n",
    "        elif epoch == 133:\n",
    "            optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr/1000, weight_decay=0.0001, momentum=0.9) \n",
    "        \n",
    "        net = net.train()        \n",
    "        epoch_accuracy = 0.0\n",
    "        epoch_iters = 0\n",
    "        for item in tqdm.tqdm(dataloader_train_norm):\n",
    "          \n",
    "            epoch_iters += 1\n",
    "            \n",
    "            inputs = item[0].to(a_device)\n",
    "            labels = item[1].long().to(a_device)\n",
    "            #print('Sizes:', inputs.size(), labels.size())\n",
    "            #print(inputs)\n",
    "            #print(labels)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            #print(outputs.size())\n",
    "            #print(outputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "#             prediction2classes(outputs)\n",
    "\n",
    "#             print(labels.cpu())\n",
    "#             print(prediction2classes(outputs))\n",
    "            epoch_accuracy += accuracy_score(labels.cpu(), prediction2classes(outputs))\n",
    "            #print(accuracy_score(labels.cpu(), prediction2classes(outputs)))\n",
    "\n",
    "        epoch_accuracy /= epoch_iters\n",
    "        train_acc.append(epoch_accuracy)\n",
    "        \n",
    "        # Make a solution after each epoch only to swiftly pass it to kaggle.\n",
    "        my_solution = make_solution(resnet, DEVICE)\n",
    "        \n",
    "        print(\"Epoch \", epoch, round(train_acc[-1], 4))\n",
    "        cur_epoch_time = time.time()\n",
    "        print('Epoch time : ', cur_epoch_time - prev_epoch_time )\n",
    "        prev_epoch_time = cur_epoch_time\n",
    "        \n",
    "        # Save modal's params after each epoch.\n",
    "        torch.save(net.state_dict(), '/content/gdrive/My Drive/my_damn_results_3_20x5')\n",
    "\n",
    "    print('Finished Training')\n",
    "    print(\"Total time : \", (time.time()-start_time))\n",
    "    \n",
    "    plt.plot(train_acc, label='Train')\n",
    "    plt.legend()\n",
    "#     plt.grid()\n",
    "    plt.grid(c='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CQSHU7tXQrZ_"
   },
   "outputs": [],
   "source": [
    "def make_solution(a_net, a_device):\n",
    "    res = []\n",
    "    net = a_net.eval()\n",
    "    for item in tqdm.tqdm(dataloader_test_norm):\n",
    "        inputs = item.to(a_device)\n",
    "        outputs = net(inputs) \n",
    "\n",
    "        res += prediction2classes(outputs)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cqXAZ-mN0h2M"
   },
   "source": [
    "The usual ResNet showed not appropriate results on the dataset given. That is why after a short research in the Internet the solution with wide ResNet was found. I tried this very implementation and it worked quite good, yeah!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-ecV9yX0G-o"
   },
   "outputs": [],
   "source": [
    "class wide_ResBlock(nn.Module):\n",
    "    def __init__(self, a_in_planes, planes, dropout_rate, stride=1):\n",
    "        super(wide_ResBlock, self).__init__()\n",
    "        \n",
    "        self.BN1 = nn.BatchNorm2d(a_in_planes)\n",
    "        self.Conv1 = nn.Conv2d(a_in_planes, planes, kernel_size=3, padding=1, bias=True)\n",
    "        self.Dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.BN2 = nn.BatchNorm2d(planes)\n",
    "        self.Conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if (stride != 1) or (a_in_planes != planes):\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(a_in_planes, planes, kernel_size=1, stride=stride, bias=True),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.BN1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.Conv1(out)\n",
    "        out = self.Dropout(out)\n",
    "        out = self.BN2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.Conv2(out)\n",
    "        out += self.shortcut(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zNxk8R0I0KZp"
   },
   "outputs": [],
   "source": [
    "class Wide_ResNet(nn.Module):\n",
    "    def __init__(self, depth, widen_factor, dropout_rate, num_classes):\n",
    "        super(Wide_ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "        n = (depth - 4) / 6\n",
    "        self.Conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.WideLayer1 = self._wide_layer(wide_ResBlock, 16 * widen_factor, n, dropout_rate, stride=1)\n",
    "        self.WideLayer2 = self._wide_layer(wide_ResBlock, 32 * widen_factor, n, dropout_rate, stride=2)\n",
    "        self.WideLayer3 = self._wide_layer(wide_ResBlock, 64 * widen_factor, n, dropout_rate, stride=2)\n",
    "        self.BN1 = nn.BatchNorm2d(64 * widen_factor, momentum=0.9)\n",
    "        self.Dense = nn.Linear(64 * widen_factor, num_classes)\n",
    "\n",
    "    def _wide_layer(self, block, planes, num_blocks, dropout_rate, stride):\n",
    "        strides = [stride] + [1] * int(num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, dropout_rate, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.Conv1(x)\n",
    "        out = self.WideLayer1(out)\n",
    "        out = self.WideLayer2(out)\n",
    "        out = self.WideLayer3(out)\n",
    "        out = self.BN1(out)\n",
    "        out = F.relu(out)\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.Dense(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rmCpF0-k--q2",
    "outputId": "664e06b1-af48-4422-ae65-d67b4699840a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 189/391 [03:52<04:06,  1.22s/it]"
     ]
    }
   ],
   "source": [
    "resnet = Wide_ResNet(28, 5, 0.3, 100)\n",
    "train_network(resnet, torch.device(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_x0_O53W_UwR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GYLWE2Km_WHJ"
   },
   "source": [
    "# Важно переключить сеть в режим eval - иначе dropout будет работать некорректно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_MzYqg_6_Ya1"
   },
   "outputs": [],
   "source": [
    "# def make_solution(a_net, a_device):\n",
    "#     res = []\n",
    "#     net = a_net.eval()\n",
    "#     for item in tqdm.tqdm(dataloader_test_norm):\n",
    "#         inputs = item.to(a_device)\n",
    "#         outputs = net(inputs) \n",
    "\n",
    "#         res += prediction2classes(outputs)\n",
    "#     return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iQSw5j8c_bf9"
   },
   "outputs": [],
   "source": [
    "# my_solution = make_solution(dense_net, DEVICE)\n",
    "my_solution = make_solution(resnet, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0OlzYS98_dVO"
   },
   "outputs": [],
   "source": [
    "file_name = DATA_PATH + 'my_solution_wide_r_6.csv'\n",
    "\n",
    "with open(file_name, 'w') as fout:\n",
    "    print('Id', 'Prediction', sep=',', file=fout)\n",
    "    for i, prediction in enumerate(my_solution):\n",
    "        print(i, prediction, sep=',', file=fout)\n",
    "        \n",
    "# from google.colab import files\n",
    "# files.download(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GZpCwD5PtUWf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Kaggle_HW4_ResNet_py3 (1).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
